{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:50:54.909066Z",
     "start_time": "2024-07-29T16:50:44.026218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from functools import wraps\n",
    "from typing import Optional, List, Dict\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from typing import Tuple\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import optuna"
   ],
   "id": "173d4fb6d3cbc0ce",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adrianinfantes/Library/Caches/pypoetry/virtualenvs/llm-sms-phising-FIp7x0oH-py3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:50:55.993231Z",
     "start_time": "2024-07-29T16:50:55.778012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configuración del logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Descarga de recursos necesarios de NLTK\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "def log_execution(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        logger.info(f\"Ejecutando {func.__name__}\")\n",
    "        result = func(*args, **kwargs)\n",
    "        logger.info(f\"Finalizado {func.__name__}\")\n",
    "        return result\n",
    "    return wrapper"
   ],
   "id": "f37a8c695a1c52b5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-29T16:50:57.370014Z",
     "start_time": "2024-07-29T16:50:57.364426Z"
    }
   },
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, file_path: str):\n",
    "        self.file_path = file_path\n",
    "        self.data: Optional[pd.DataFrame] = None\n",
    "\n",
    "    @log_execution\n",
    "    def load_data(self, encoding: str = 'utf-8') -> None:\n",
    "        \"\"\"\n",
    "        Carga los datos desde el archivo CSV.\n",
    "        \n",
    "        Args:\n",
    "            encoding (str): La codificación del archivo. Por defecto es 'utf-8'.\n",
    "        \"\"\"\n",
    "        encodings_to_try = [encoding, 'iso-8859-1', 'latin1', 'cp1252']\n",
    "        \n",
    "        for enc in encodings_to_try:\n",
    "            try:\n",
    "                self.data = pd.read_csv(self.file_path, encoding=enc)\n",
    "                logger.info(f\"Datos cargados exitosamente desde {self.file_path} con codificación {enc}\")\n",
    "                return\n",
    "            except UnicodeDecodeError:\n",
    "                logger.warning(f\"No se pudo cargar el archivo con la codificación {enc}. Probando otra...\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error al cargar los datos: {str(e)}\")\n",
    "                raise\n",
    "        \n",
    "        logger.error(\"No se pudo cargar el archivo con ninguna de las codificaciones probadas.\")\n",
    "        raise ValueError(\"No se pudo determinar la codificación correcta del archivo.\")\n",
    "\n",
    "    @log_execution\n",
    "    def get_info(self) -> None:\n",
    "        \"\"\"Muestra información básica sobre el dataset.\"\"\"\n",
    "        if self.data is not None:\n",
    "            logger.info(\"Información del dataset:\")\n",
    "            print(self.data.info())\n",
    "        else:\n",
    "            logger.warning(\"No hay datos cargados. Ejecute load_data() primero.\")\n",
    "\n",
    "    @log_execution\n",
    "    def check_nulls(self) -> pd.DataFrame:\n",
    "        \"\"\"Verifica y retorna información sobre valores nulos en el dataset.\"\"\"\n",
    "        if self.data is not None:\n",
    "            null_info = self.data.isnull().sum().reset_index()\n",
    "            null_info.columns = ['Columna', 'Nulos']\n",
    "            null_info['Porcentaje'] = (null_info['Nulos'] / len(self.data)) * 100\n",
    "            logger.info(\"Información de valores nulos:\")\n",
    "            print(null_info)\n",
    "            return null_info\n",
    "        else:\n",
    "            logger.warning(\"No hay datos cargados. Ejecute load_data() primero.\")\n",
    "            return pd.DataFrame()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:50:57.813144Z",
     "start_time": "2024-07-29T16:50:57.805683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ejemplo de uso\n",
    "\n",
    "loader = DataLoader(\"../data/raw_data/SMS_raw_data.csv\")\n",
    "loader.load_data()"
   ],
   "id": "a46abcedb4ddaf58",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 18:50:57,806 - INFO - Ejecutando load_data\n",
      "2024-07-29 18:50:57,808 - WARNING - No se pudo cargar el archivo con la codificación utf-8. Probando otra...\n",
      "2024-07-29 18:50:57,811 - INFO - Datos cargados exitosamente desde ../data/raw_data/SMS_raw_data.csv con codificación iso-8859-1\n",
      "2024-07-29 18:50:57,811 - INFO - Finalizado load_data\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:50:58.337820Z",
     "start_time": "2024-07-29T16:50:58.329475Z"
    }
   },
   "cell_type": "code",
   "source": "loader.get_info()",
   "id": "71d10200bfe8a767",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 18:50:58,330 - INFO - Ejecutando get_info\n",
      "2024-07-29 18:50:58,330 - INFO - Información del dataset:\n",
      "2024-07-29 18:50:58,336 - INFO - Finalizado get_info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 957 entries, 0 to 956\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   S. No.        957 non-null    int64 \n",
      " 1   Message_body  957 non-null    object\n",
      " 2   Label         957 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 22.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:50:58.965858Z",
     "start_time": "2024-07-29T16:50:58.952989Z"
    }
   },
   "cell_type": "code",
   "source": "loader.check_nulls()",
   "id": "70ebe5fcb2816131",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 18:50:58,953 - INFO - Ejecutando check_nulls\n",
      "2024-07-29 18:50:58,955 - INFO - Información de valores nulos:\n",
      "2024-07-29 18:50:58,958 - INFO - Finalizado check_nulls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Columna  Nulos  Porcentaje\n",
      "0        S. No.      0         0.0\n",
      "1  Message_body      0         0.0\n",
      "2         Label      0         0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        Columna  Nulos  Porcentaje\n",
       "0        S. No.      0         0.0\n",
       "1  Message_body      0         0.0\n",
       "2         Label      0         0.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Columna</th>\n",
       "      <th>Nulos</th>\n",
       "      <th>Porcentaje</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S. No.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Message_body</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Label</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:51:00.201393Z",
     "start_time": "2024-07-29T16:51:00.195799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Vemos las primeras filas del dataset\n",
    "\n",
    "loader.data.head()"
   ],
   "id": "6963668c89cae158",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   S. No.                                       Message_body     Label\n",
       "0       1                         Rofl. Its true to its name  Non-Spam\n",
       "1       2  The guy did some bitching but I acted like i'd...  Non-Spam\n",
       "2       3  Pity, * was in mood for that. So...any other s...  Non-Spam\n",
       "3       4               Will ü b going to esplanade fr home?  Non-Spam\n",
       "4       5  This is the 2nd time we have tried 2 contact u...      Spam"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S. No.</th>\n",
       "      <th>Message_body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>Non-Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>Non-Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>Non-Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>Non-Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:51:04.506050Z",
     "start_time": "2024-07-29T16:51:04.500944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.copy()\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text: str) -> str:\n",
    "        \"\"\"\n",
    "        Limpia el texto: elimina caracteres especiales, convierte a minúsculas,\n",
    "        elimina stopwords y tokeniza.\n",
    "        \"\"\"\n",
    "        # Convertir a minúsculas\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Eliminar caracteres especiales y números\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        \n",
    "        # Tokenizar\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # Eliminar stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "        \n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    def process_data(self) -> 'DataProcessor':\n",
    "        \"\"\"\n",
    "        Procesa los datos: limpia el texto y codifica las etiquetas.\n",
    "        \"\"\"\n",
    "        logger.info(\"Iniciando procesamiento de datos...\")\n",
    "\n",
    "        # Limpiar el texto de la columna 'Message_body'\n",
    "        self.df['cleaned_text'] = self.df['Message_body'].apply(self.clean_text)\n",
    "        logger.info(\"Texto limpiado exitosamente.\")\n",
    "\n",
    "        # Convertir la columna 'Label' a valores numéricos\n",
    "        self.df['numeric_label'] = (self.df['Label'] == 'Spam').astype(int)\n",
    "        logger.info(\"Etiquetas convertidas a valores numéricos.\")\n",
    "\n",
    "        # Eliminar las columnas originales\n",
    "        self.df.drop(['Message_body', 'Label'], axis=1, inplace=True)\n",
    "        logger.info(\"Columnas originales eliminadas.\")\n",
    "\n",
    "        logger.info(\"Procesamiento de datos completado.\")\n",
    "        return self\n",
    "\n",
    "    def get_processed_data(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Devuelve el DataFrame procesado.\n",
    "        \"\"\"\n",
    "        if 'cleaned_text' not in self.df.columns or 'numeric_label' not in self.df.columns:\n",
    "            raise ValueError(\"Los datos aún no han sido procesados. Ejecute process_data() primero.\")\n",
    "        return self.df"
   ],
   "id": "de5b0c105dbc6fcf",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:51:06.989930Z",
     "start_time": "2024-07-29T16:51:06.897193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ejemplo de uso\n",
    "    \n",
    "processor = DataProcessor(loader.data)\n",
    "processor = processor.process_data()"
   ],
   "id": "5970210ae6ab3ab8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 18:51:06,898 - INFO - Iniciando procesamiento de datos...\n",
      "2024-07-29 18:51:06,985 - INFO - Texto limpiado exitosamente.\n",
      "2024-07-29 18:51:06,987 - INFO - Etiquetas convertidas a valores numéricos.\n",
      "2024-07-29 18:51:06,988 - INFO - Columnas originales eliminadas.\n",
      "2024-07-29 18:51:06,988 - INFO - Procesamiento de datos completado.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:51:07.799655Z",
     "start_time": "2024-07-29T16:51:07.795897Z"
    }
   },
   "cell_type": "code",
   "source": "processor.df.head()",
   "id": "7c3544b81a6d41e6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   S. No.                                       cleaned_text  numeric_label\n",
       "0       1                                     rofl true name              0\n",
       "1       2  guy bitching acted like id interested buying s...              0\n",
       "2       3                        pity mood soany suggestions              0\n",
       "3       4                          b going esplanade fr home              0\n",
       "4       5  nd time tried contact u u pound prize claim ea...              1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S. No.</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>numeric_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rofl true name</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>guy bitching acted like id interested buying s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>pity mood soany suggestions</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>b going esplanade fr home</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>nd time tried contact u u pound prize claim ea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:51:08.907256Z",
     "start_time": "2024-07-29T16:51:08.897653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Guardar el DataFrame procesado\n",
    "processor.df.to_csv(\"../data/processed_data/processed_sms_data.csv\", index=False)"
   ],
   "id": "6c5a26e7df1965be",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:51:10.503191Z",
     "start_time": "2024-07-29T16:51:10.498462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EmbeddingProcessor:\n",
    "    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        logger.info(f\"Modelo {model_name} cargado exitosamente.\")\n",
    "\n",
    "    def generate_embeddings(self, texts: Union[List[str], pd.Series]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Genera embeddings para una lista de textos o una Serie de pandas.\n",
    "        \"\"\"\n",
    "        logger.info(\"Generando embeddings...\")\n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        logger.info(\"Embeddings generados exitosamente.\")\n",
    "        return embeddings\n",
    "\n",
    "    def process_dataframe(self, df: pd.DataFrame, text_column: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Procesa un DataFrame, generando embeddings para la columna de texto especificada\n",
    "        y los combina en una sola columna.\n",
    "        \"\"\"\n",
    "        if text_column not in df.columns:\n",
    "            raise ValueError(f\"La columna {text_column} no existe en el DataFrame.\")\n",
    "\n",
    "        embeddings = self.generate_embeddings(df[text_column])\n",
    "        \n",
    "        # Convertir los embeddings a una lista de listas para almacenarlos en una sola columna\n",
    "        embeddings_list = embeddings.tolist()\n",
    "        \n",
    "        # Añadir los embeddings como una nueva columna al DataFrame\n",
    "        df['combined_embeddings'] = embeddings_list\n",
    "        \n",
    "        logger.info(f\"DataFrame procesado. Embeddings combinados en una sola columna.\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def get_embedding_dim(df: pd.DataFrame) -> int:\n",
    "        \"\"\"\n",
    "        Obtiene la dimensión de los embeddings combinados.\n",
    "        \"\"\"\n",
    "        if 'combined_embeddings' not in df.columns:\n",
    "            raise ValueError(\"El DataFrame no contiene la columna 'combined_embeddings'.\")\n",
    "        \n",
    "        # Asumimos que todos los embeddings tienen la misma dimensión\n",
    "        embedding_dim = len(df['combined_embeddings'].iloc[0])\n",
    "        return embedding_dim"
   ],
   "id": "5740f59de7e9ec6a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:51:15.417077Z",
     "start_time": "2024-07-29T16:51:11.234110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ejemplo de uso\n",
    "embedding_processor = EmbeddingProcessor()\n",
    "df_with_embeddings = embedding_processor.process_dataframe(processor.df, 'cleaned_text')"
   ],
   "id": "aafd3eeb88747172",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 18:51:11,249 - INFO - Use pytorch device_name: mps\n",
      "2024-07-29 18:51:11,249 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2024-07-29 18:51:13,140 - INFO - Modelo all-MiniLM-L6-v2 cargado exitosamente.\n",
      "2024-07-29 18:51:13,142 - INFO - Generando embeddings...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/30 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3253358f3c04a97a8149a1d3ce829de"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 18:51:15,407 - INFO - Embeddings generados exitosamente.\n",
      "2024-07-29 18:51:15,415 - INFO - DataFrame procesado. Embeddings combinados en una sola columna.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:51:16.731329Z",
     "start_time": "2024-07-29T16:51:16.728715Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"Número de características de embedding: {df_with_embeddings.filter(like='embedding_').shape[1]}\")",
   "id": "fbfe4dab2141f091",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de características de embedding: 0\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:51:18.091085Z",
     "start_time": "2024-07-29T16:51:18.081515Z"
    }
   },
   "cell_type": "code",
   "source": "df_with_embeddings.head()",
   "id": "3ed6852af9dbbf3a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   S. No.                                       cleaned_text  numeric_label  \\\n",
       "0       1                                     rofl true name              0   \n",
       "1       2  guy bitching acted like id interested buying s...              0   \n",
       "2       3                        pity mood soany suggestions              0   \n",
       "3       4                          b going esplanade fr home              0   \n",
       "4       5  nd time tried contact u u pound prize claim ea...              1   \n",
       "\n",
       "                                 combined_embeddings  \n",
       "0  [-0.044475845992565155, -0.04105318337678909, ...  \n",
       "1  [-0.055322881788015366, -0.020870674401521683,...  \n",
       "2  [-0.054527826607227325, 0.035373345017433167, ...  \n",
       "3  [0.027759529650211334, 0.011844214983284473, 0...  \n",
       "4  [-0.0534316711127758, 0.03708187863230705, 0.0...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S. No.</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>numeric_label</th>\n",
       "      <th>combined_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rofl true name</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.044475845992565155, -0.04105318337678909, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>guy bitching acted like id interested buying s...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.055322881788015366, -0.020870674401521683,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>pity mood soany suggestions</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.054527826607227325, 0.035373345017433167, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>b going esplanade fr home</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.027759529650211334, 0.011844214983284473, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>nd time tried contact u u pound prize claim ea...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.0534316711127758, 0.03708187863230705, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:51:26.772615Z",
     "start_time": "2024-07-29T16:51:26.547159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Guardar el DataFrame con embeddings\n",
    "df_with_embeddings.to_csv(\"../data/processed_data/embedded_sms_data.csv\", index=False)"
   ],
   "id": "edb626b53f39cf29",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:51:28.294198Z",
     "start_time": "2024-07-29T16:51:28.289282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import logging\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class AutoencoderModel(nn.Module):\n",
    "    def __init__(self, input_dim: int, encoding_dim: int = 32):\n",
    "        super(AutoencoderModel, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.encoding_dim = encoding_dim\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, encoding_dim)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ],
   "id": "3fdc2fbaed03aa37",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:51:31.802761Z",
     "start_time": "2024-07-29T16:51:31.788966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AutoencoderTrainer:\n",
    "    def __init__(self, df: pd.DataFrame, embedding_col: str = 'combined_embeddings', \n",
    "                 label_col: str = 'numeric_label', test_size: float = 0.2, \n",
    "                 random_state: int = 42, batch_size: int = 32, encoding_dim: int = 32):\n",
    "        self.df = df\n",
    "        self.embedding_col = embedding_col\n",
    "        self.label_col = label_col\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.batch_size = batch_size\n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.model = None\n",
    "        self.train_loader = None\n",
    "        self.test_loader = None\n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "\n",
    "    def prepare_data(self):\n",
    "        logger.info(\"Preparando datos para el autoencoder...\")\n",
    "        \n",
    "        X = np.array(self.df[self.embedding_col].tolist())\n",
    "        y = self.df[self.label_col].values\n",
    "        \n",
    "        # Aplicar SMOTE para manejar el desequilibrio de clases\n",
    "        smote = SMOTE(random_state=self.random_state)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "        \n",
    "        X_train, self.X_test, y_train, self.y_test = train_test_split(X_resampled, y_resampled, test_size=self.test_size, random_state=self.random_state)\n",
    "        \n",
    "        X_train_tensor = torch.FloatTensor(X_train)\n",
    "        X_test_tensor = torch.FloatTensor(self.X_test)\n",
    "        y_train_tensor = torch.FloatTensor(y_train)\n",
    "        y_test_tensor = torch.FloatTensor(self.y_test)\n",
    "        \n",
    "        # Crear un WeightedRandomSampler para manejar el desequilibrio en el entrenamiento\n",
    "        class_counts = np.bincount(y_train.astype(int))\n",
    "        class_weights = 1. / class_counts\n",
    "        sample_weights = class_weights[y_train.astype(int)]\n",
    "        sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
    "        \n",
    "        self.train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=self.batch_size, sampler=sampler)\n",
    "        self.test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=self.batch_size, shuffle=False)\n",
    "        \n",
    "        logger.info(f\"Datos preparados. Tamaño del conjunto de entrenamiento: {len(X_train)}, Tamaño del conjunto de prueba: {len(self.X_test)}\")\n",
    "        \n",
    "        return self.train_loader, self.test_loader\n",
    "\n",
    "    def create_model(self):\n",
    "        input_dim = len(self.df[self.embedding_col].iloc[0])\n",
    "        self.model = AutoencoderModel(input_dim, self.encoding_dim)\n",
    "        logger.info(f\"Modelo creado con dimensión de entrada {input_dim} y dimensión de codificación {self.encoding_dim}\")\n",
    "        return self.model\n",
    "\n",
    "    def train_model(self, num_epochs: int = 300, learning_rate: float = 0.001):\n",
    "        if self.model is None or self.train_loader is None:\n",
    "            raise ValueError(\"El modelo no ha sido creado o los datos no han sido preparados.\")\n",
    "        \n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        logger.info(\"Iniciando entrenamiento del modelo...\")\n",
    "        for epoch in range(num_epochs):\n",
    "            self.model.train()\n",
    "            train_loss = 0.0\n",
    "            for batch_features, _ in self.train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(batch_features)\n",
    "                loss = criterion(outputs, batch_features)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            if (epoch + 1) % 20 == 0:\n",
    "                logger.info(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss/len(self.train_loader):.4f}')\n",
    "        \n",
    "        logger.info(\"Entrenamiento completado.\")\n",
    "\n",
    "    def find_optimal_threshold(self, step: float = 0.001):\n",
    "        all_losses = []\n",
    "        all_labels = []\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_features, batch_labels in self.test_loader:\n",
    "                outputs = self.model(batch_features)\n",
    "                loss = nn.MSELoss(reduction='none')(outputs, batch_features)\n",
    "                loss = loss.mean(axis=1)\n",
    "                all_losses.extend(loss.tolist())\n",
    "                all_labels.extend(batch_labels.tolist())\n",
    "        \n",
    "        thresholds = np.arange(min(all_losses), max(all_losses), step)\n",
    "        f1_scores = []\n",
    "        \n",
    "        for threshold in thresholds:\n",
    "            predictions = [1 if loss < threshold else 0 for loss in all_losses]\n",
    "            f1 = f1_score(all_labels, predictions)\n",
    "            f1_scores.append(f1)\n",
    "        \n",
    "        optimal_idx = np.argmax(f1_scores)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        \n",
    "        return optimal_threshold\n",
    "\n",
    "    def evaluate_model(self, threshold: float = None):\n",
    "        if self.model is None or self.test_loader is None:\n",
    "            raise ValueError(\"El modelo no ha sido creado o entrenado, o los datos de prueba no han sido preparados.\")\n",
    "        \n",
    "        if threshold is None:\n",
    "            threshold = self.find_optimal_threshold()\n",
    "        \n",
    "        self.model.eval()\n",
    "        all_losses = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_features, batch_labels in self.test_loader:\n",
    "                outputs = self.model(batch_features)\n",
    "                loss = nn.MSELoss(reduction='none')(outputs, batch_features)\n",
    "                loss = loss.mean(axis=1)\n",
    "                all_losses.extend(loss.tolist())\n",
    "                all_labels.extend(batch_labels.tolist())\n",
    "        \n",
    "        all_predictions = [1 if loss < threshold else 0 for loss in all_losses]\n",
    "        \n",
    "        precision = precision_score(all_labels, all_predictions)\n",
    "        recall = recall_score(all_labels, all_predictions)\n",
    "        f1 = f1_score(all_labels, all_predictions)\n",
    "        auc_roc = roc_auc_score(all_labels, [-loss for loss in all_losses])\n",
    "        cm = confusion_matrix(all_labels, all_predictions)\n",
    "        \n",
    "        logger.info(f\"Evaluación con umbral óptimo: {threshold:.4f}\")\n",
    "        logger.info(f\"Precisión: {precision:.4f}\")\n",
    "        logger.info(f\"Recall: {recall:.4f}\")\n",
    "        logger.info(f\"F1-Score: {f1:.4f}\")\n",
    "        logger.info(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "        logger.info(f\"Matriz de Confusión:\\n{cm}\")\n",
    "        \n",
    "        return {\n",
    "            \"threshold\": threshold,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1,\n",
    "            \"auc_roc\": auc_roc,\n",
    "            \"confusion_matrix\": cm\n",
    "        }"
   ],
   "id": "40388da0d9aeb98c",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:51:35.540710Z",
     "start_time": "2024-07-29T16:51:35.461047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = AutoencoderTrainer(df_with_embeddings)\n",
    "train_loader, test_loader = trainer.prepare_data()"
   ],
   "id": "bb0a05db4ec9c680",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 18:51:35,461 - INFO - Preparando datos para el autoencoder...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2024-07-29 18:51:35,538 - INFO - Datos preparados. Tamaño del conjunto de entrenamiento: 1336, Tamaño del conjunto de prueba: 334\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:51:55.149567Z",
     "start_time": "2024-07-29T16:51:39.471127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = trainer.create_model()\n",
    "trainer.train_model(num_epochs=300)"
   ],
   "id": "7e9c4338695f42b2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 18:51:39,476 - INFO - Modelo creado con dimensión de entrada 384 y dimensión de codificación 32\n",
      "2024-07-29 18:51:39,477 - INFO - Iniciando entrenamiento del modelo...\n",
      "2024-07-29 18:51:40,907 - INFO - Epoch [20/300], Loss: 0.0013\n",
      "2024-07-29 18:51:41,893 - INFO - Epoch [40/300], Loss: 0.0011\n",
      "2024-07-29 18:51:42,847 - INFO - Epoch [60/300], Loss: 0.0010\n",
      "2024-07-29 18:51:43,815 - INFO - Epoch [80/300], Loss: 0.0010\n",
      "2024-07-29 18:51:44,888 - INFO - Epoch [100/300], Loss: 0.0010\n",
      "2024-07-29 18:51:45,991 - INFO - Epoch [120/300], Loss: 0.0010\n",
      "2024-07-29 18:51:47,058 - INFO - Epoch [140/300], Loss: 0.0010\n",
      "2024-07-29 18:51:48,192 - INFO - Epoch [160/300], Loss: 0.0009\n",
      "2024-07-29 18:51:49,270 - INFO - Epoch [180/300], Loss: 0.0010\n",
      "2024-07-29 18:51:50,262 - INFO - Epoch [200/300], Loss: 0.0009\n",
      "2024-07-29 18:51:51,222 - INFO - Epoch [220/300], Loss: 0.0009\n",
      "2024-07-29 18:51:52,198 - INFO - Epoch [240/300], Loss: 0.0009\n",
      "2024-07-29 18:51:53,195 - INFO - Epoch [260/300], Loss: 0.0009\n",
      "2024-07-29 18:51:54,163 - INFO - Epoch [280/300], Loss: 0.0009\n",
      "2024-07-29 18:51:55,147 - INFO - Epoch [300/300], Loss: 0.0009\n",
      "2024-07-29 18:51:55,147 - INFO - Entrenamiento completado.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:51:56.431943Z",
     "start_time": "2024-07-29T16:51:56.408670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "metrics = trainer.evaluate_model()\n",
    "print(metrics)"
   ],
   "id": "ef01f5bbc09ec89b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 18:51:56,429 - INFO - Evaluación con umbral óptimo: 0.0010\n",
      "2024-07-29 18:51:56,429 - INFO - Precisión: 0.9634\n",
      "2024-07-29 18:51:56,429 - INFO - Recall: 0.9753\n",
      "2024-07-29 18:51:56,430 - INFO - F1-Score: 0.9693\n",
      "2024-07-29 18:51:56,430 - INFO - AUC-ROC: 0.9966\n",
      "2024-07-29 18:51:56,430 - INFO - Matriz de Confusión:\n",
      "[[166   6]\n",
      " [  4 158]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'threshold': np.float64(0.0010215527488762746), 'precision': np.float64(0.9634146341463414), 'recall': np.float64(0.9753086419753086), 'f1_score': np.float64(0.9693251533742331), 'auc_roc': np.float64(0.9965546942291128), 'confusion_matrix': array([[166,   6],\n",
      "       [  4, 158]])}\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:52:03.286489Z",
     "start_time": "2024-07-29T16:52:03.280532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Guardar el modelo\n",
    "\n",
    "torch.save({\n",
    "    'state_dict': model.state_dict(),\n",
    "    'input_dim': model.input_dim,\n",
    "    'encoding_dim': model.encoding_dim\n",
    "}, \"../models/autoencoder_model.pth\")"
   ],
   "id": "8a26573caec30b87",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:53:45.471888Z",
     "start_time": "2024-07-29T16:53:45.460717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from typing import List, Union\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class PhishingPredictor:\n",
    "    def __init__(self, model_path: str, embedding_model: str = 'all-MiniLM-L6-v2', threshold: float = 0.0010):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = self.load_model(model_path)\n",
    "        self.embedding_model = SentenceTransformer(embedding_model)\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def load_model(self, model_path: str):\n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        input_dim = checkpoint['input_dim']\n",
    "        encoding_dim = checkpoint['encoding_dim']\n",
    "        model = AutoencoderModel(input_dim, encoding_dim)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "    def preprocess_text(self, text: str) -> str:\n",
    "        return text.lower()  # Este es un ejemplo simple, ajusta según tus necesidades\n",
    "\n",
    "    def generate_embedding(self, text: str) -> np.ndarray:\n",
    "        return self.embedding_model.encode([text])[0]\n",
    "\n",
    "    def predict(self, text: Union[str, List[str]]) -> Union[bool, List[bool]]:\n",
    "        if isinstance(text, str):\n",
    "            text = [text]\n",
    "        \n",
    "        processed_texts = [self.preprocess_text(t) for t in text]\n",
    "        embeddings = [self.generate_embedding(t) for t in processed_texts]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            input_tensor = torch.FloatTensor(embeddings).to(self.device)\n",
    "            outputs = self.model(input_tensor)\n",
    "            losses = torch.mean(torch.pow(outputs - input_tensor, 2), dim=1)\n",
    "        \n",
    "        predictions = [loss.item() < self.threshold for loss in losses]\n",
    "        \n",
    "        return predictions[0] if len(predictions) == 1 else predictions\n",
    "\n",
    "    def predict_with_confidence(self, text: Union[str, List[str]]) -> Union[dict, List[dict]]:\n",
    "        if isinstance(text, str):\n",
    "            text = [text]\n",
    "        \n",
    "        processed_texts = [self.preprocess_text(t) for t in text]\n",
    "        embeddings = [self.generate_embedding(t) for t in processed_texts]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            input_tensor = torch.FloatTensor(embeddings).to(self.device)\n",
    "            outputs = self.model(input_tensor)\n",
    "            losses = torch.mean(torch.pow(outputs - input_tensor, 2), dim=1)\n",
    "        \n",
    "        results = []\n",
    "        for loss in losses:\n",
    "            loss_value = loss.item()\n",
    "            is_phishing = loss_value < self.threshold\n",
    "            confidence = 1 - (loss_value / self.threshold) if is_phishing else (loss_value / self.threshold) - 1\n",
    "            confidence = max(min(confidence, 1), 0)  # Clip confidence to [0, 1]\n",
    "            results.append({\n",
    "                \"is_phishing\": is_phishing,\n",
    "                \"confidence\": confidence\n",
    "            })\n",
    "        \n",
    "        return results[0] if len(results) == 1 else results"
   ],
   "id": "e4cea6505cbe7e18",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:53:48.228014Z",
     "start_time": "2024-07-29T16:53:46.536743Z"
    }
   },
   "cell_type": "code",
   "source": "predictor = PhishingPredictor(\"../models/autoencoder_model.pth\")",
   "id": "b9916d12ccc1c7e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wc/lkhs06_13qdbtd7gv1ffzts80000gn/T/ipykernel_16434/3144122690.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=self.device)\n",
      "2024-07-29 18:53:46,545 - INFO - Use pytorch device_name: mps\n",
      "2024-07-29 18:53:46,545 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:53:51.559899Z",
     "start_time": "2024-07-29T16:53:51.221704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Predicción simple\n",
    "result = predictor.predict(\"Este es un mensaje de prueba\")\n",
    "print(f\"¿Es phishing? {result}\")"
   ],
   "id": "ba7b89a5db17a90d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "138b1be2ebb643d9ac5e1aa07c10764f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Es phishing? False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wc/lkhs06_13qdbtd7gv1ffzts80000gn/T/ipykernel_16434/3144122690.py:36: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:281.)\n",
      "  input_tensor = torch.FloatTensor(embeddings).to(self.device)\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:53:56.151585Z",
     "start_time": "2024-07-29T16:53:56.070370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Predicción con confianza\n",
    "result_with_confidence = predictor.predict_with_confidence(\"Este es un mensaje de prueba\")\n",
    "print(f\"Predicción: {result_with_confidence['is_phishing']}, Confianza: {result_with_confidence['confidence']:.2f}\")"
   ],
   "id": "f552fd34c6b44e8b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff88f08e901e4121bb8866051ff7f52e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción: False, Confianza: 1.00\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:00:54.719366Z",
     "start_time": "2024-07-29T16:00:54.712889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import List, Union\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "class PhishingDetectorInterface:\n",
    "    def __init__(self, model_path: str):\n",
    "        self.predictor = PhishingPredictor(model_path)\n",
    "\n",
    "    def predict_phishing(self, message: str) -> tuple:\n",
    "        result = self.predictor.predict_with_confidence(message)\n",
    "        \n",
    "        is_phishing = result['is_phishing']\n",
    "        confidence = result['confidence']\n",
    "        \n",
    "        # Calcular porcentajes\n",
    "        phishing_percentage = confidence * 100 if is_phishing else (1 - confidence) * 100\n",
    "        not_phishing_percentage = 100 - phishing_percentage\n",
    "\n",
    "        # Preparar el resultado para Gradio\n",
    "        if is_phishing:\n",
    "            label = \"Phishing\"\n",
    "            color = \"#FF0000\"  # Rojo para phishing\n",
    "        else:\n",
    "            label = \"No Phishing\"\n",
    "            color = \"#00FF00\"  # Verde para no phishing\n",
    "        \n",
    "        return (\n",
    "            label,\n",
    "            f\"Phishing: {phishing_percentage:.2f}%\",\n",
    "            f\"Not Phishing: {not_phishing_percentage:.2f}%\",\n",
    "            color\n",
    "        )\n",
    "\n",
    "    def launch(self):\n",
    "        iface = gr.Interface(\n",
    "            fn=self.predict_phishing,\n",
    "            inputs=gr.Textbox(lines=5, label=\"Enter the message here\"),\n",
    "            outputs=[\n",
    "                gr.Textbox(label=\"Prediction\"),\n",
    "                gr.Textbox(label=\"Phishing Probability\"),\n",
    "                gr.Textbox(label=\"Not Phishing Probability\"),\n",
    "                gr.ColorPicker(label=\"Indicator\")\n",
    "            ],\n",
    "            title=\"Phishing Detection using Autoencoder\",\n",
    "            description=\"Enter a message to check if it's phishing or not.\"\n",
    "        )\n",
    "        iface.launch()"
   ],
   "id": "debe9a6e0858a37a",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T16:00:57.363673Z",
     "start_time": "2024-07-29T16:00:55.580483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Uso\n",
    "\n",
    "model_path = \"../models/autoencoder_model.pth\"\n",
    "interface = PhishingDetectorInterface(model_path)\n",
    "interface.launch()"
   ],
   "id": "63d7aca882adb4b9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wc/lkhs06_13qdbtd7gv1ffzts80000gn/T/ipykernel_13682/1313728859.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path, map_location=self.device)\n",
      "2024-07-29 18:00:55,586 - INFO - Use pytorch device_name: mps\n",
      "2024-07-29 18:00:55,587 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2024-07-29 18:00:57,352 - INFO - HTTP Request: GET http://127.0.0.1:7862/startup-events \"HTTP/1.1 200 OK\"\n",
      "2024-07-29 18:00:57,359 - INFO - HTTP Request: HEAD http://127.0.0.1:7862/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7808383cd673f686"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
